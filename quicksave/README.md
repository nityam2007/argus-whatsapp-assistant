# Quicksave (Ex-CEP v12.2) 快存

**Context Extension Protocol** — Cross-model context handoff via Japanese semantic compression and negentropic coherence validation.

<img width="2752" height="1536" alt="unnamed (2)" src="https://github.com/user-attachments/assets/5006ace7-2017-4e68-a1a8-33f5f7797b26" />

> *"What must be preserved for a fresh model instance to continue this work?"*

## Install
**Onboarding**
Due to model guards please paste the onboarding.md into your LLM - It teaches it the skill immediately so it won't cut corners reading the references. 

**Claude Desktop / Claude Code:**
```bash
npx ai-agent-skills install ktg-one/quicksave
```

**Everyone Else:**
1. Download this folder (clone or ZIP)
2. Upload all `.md` files to your project/context

## The Problem

Context windows are finite. Platform compaction is lossy. Cross-model handoffs lose critical relationships. Your 3-hour session becomes a shallow bullet list.

## The Solution

Quicksave v9.1 creates **carry-packets** using:
- **Progressive Density Layering (PDL)** — 4-layer information hierarchy
- **Japanese Kanji Compression** — 40-55% token reduction
- **Negentropic Coherence Lattice (NCL)** — Drift validation before handoff **DESERVES IT'S OWN BLOGPOST**
- **System 2 Attention (S2A)** — Noise filtering for LLM efficiency
- **Multi-Layer Density of Experts (MLDoE)** — 5-Embodied Chain of Density

## On top of:
- Universal Self Consistency
- Attentive Reasoning Queries
- Chain of Verification
- Confidence scoring

**Target:** 0.15-0.17 entity/token — the density where LLMs achieve optimal recall.

## Benchmarks

| Metric | Result |
|--------|--------|
| Density | ~0.15 |
| Forensic recall | 9.5/10 |
| Cross-domain preservation | 97% |
| Model acceptance | 99% |
| Production testing | 19 months (ktg.one) |

## Usage

| Trigger | Action |
|---------|--------|
| `/handoff` `/Quicksave` `/packet` | Generate transfer packet |
| `/quicksave` `/qs` | Generate validated packet |
| Context ≥80% | Auto-prompts to save |
| "continue later" | Offer quicksave |

### Transfer to Another Model

1. Say `/handoff` in current session
2. Copy the YAML packet
3. Paste into new session: "Continue from this context packet: [paste]"

## Core Components

### PDL 4層 (Progressive Density Layering)

| Layer | Content | Keys |
|-------|---------|------|
| L1 知識層 | Facts, decisions, definitions | d/r/c/f/s |
| L2 関係層 | ConQuicksavet edges, domain bridges | 起/終/関/xd/w |
| L3 文脈層 | Reasoning patterns, principles | — |
| L4 超認知層 | Style, tension, user traits | — |

**L2 is what summarization loses.** Quicksave preserves it.

### Japanese Compression 漢字圧縮

```
English: "cross-domain relationship preservation" (5 tokens)
Japanese: "領域横断関係保存" (2 tokens, 4 entities)
```

### NCL Validation 整合性検証

7 drift metrics catch failure before handoff:

| Metric | Detects |
|--------|---------|
| σ_axis | Plan vs execution misalignment |
| σ_loop | Internal contradiction |
| ω_world | Reality disconnect |
| λ_vague | Content-free smoothing |
| σ_leak | Constraint erosion |
| ρ_fab | Hallucination |
| λ_thrash | High activity, low progress |

If σ7_drift > 3.0 → packet flagged, requires verification.

### S2A (System 2 Attention)

Noise filtering optimized for LLM efficiency. Removes:
- Conversational fluff
- Redundant context
- Low-signal exchanges

### MLDoE (Multi-Layer Density of Experts)

3-layer compression with 5-iteration Chain of Density. Expert council ensures quality:
- Memory Architect → preservation list
- Cross-Domain Analyst → edge map
- Compression Specialist → density optimization
- Restoration Engineer → cold-start validation

### Four Roles Governance

AXIS/LYRA/RHO/NYX archetypal oversight for quality assurance.

### Anti-Injection Architecture

5 trust signals that receiving models recognize as collaboration, not control:
1. **来歴** — source_model + timestamp
2. **同意** — user_initiated: true
3. **宣言** — this_is / this_is_not framing
4. **許可** — "you may" not "you must"
5. **確認** — verify with user if unsure

## Files

```
Quicksave-agent-skill/
├── SKILL.md                    # Core protocol
└── references/
    ├── PDL.md                  # Progressive Density Layering
    ├── S2A.md                  # System 2 Attention
    ├── NCL.md                  # Negentropic Coherence Lattice
    ├── NCL-CONTRIBUTION.md     # David Tubbs attribution
    ├── MLDOE.md                # Multi-Layer Density of Experts
    ├── MIRAS.md                # Memory architecture
    ├── KANJI.md                # Compression dictionary
    ├── XDOMAIN.md              # Cross-domain preservation
    ├── CASCADE.md              # ARQ/CoVE/USC integration
    ├── EXPERTS.md              # Council overview
    ├── ANTI-INJECTION.md       # Trust architecture
    ├── PROTOCOL.md             # Full YAML schema
    └── INDEX.md                # Reference index
```

## Tested Models

Claude ✓ | GPT-4/4o ✓ | Gemini ✓ | Qwen ✓ | DeepSeek ✓ | KIMIK2 ✓ | Qwen ✓ | Grok4 ✓ 

## Part of STRAWHATS Framework

Quicksave is the context preservation component of **STRAWHATS** (Strategic Triumvirate Router Architecture With Hybrid Agentic Task Systems).

## Contributors

**Kevin Tan** (ktg.one) — Quicksave protocol, PDL, S2A, MLDoE, Japanese compression, 19-month production validation

**David Tubbs** (Axis_42) — Negentropic Coherence Lattice, Four Roles governance, ~30% robustness enhancement

## License

MIT — [ktg.one](https://ktg.one)

---

*0.15 density. 97% preservation. 9.5/10 recall. NCL validated.*

---

### User Responsibility Clarification
- **Packet upkeep is yours** — what to save, when, what to discard
- **Key nodes are your choice** — you decide what's critical for your work
- **Model retention varies** — different AIs handle context differently; adapt accordingly
- **Language is personal** — technical jargon, casual tone, domain terminology; use what fits
- **Format is flexible** — 4-layer structure is a guide, not a mandate

Quicksave is infrastructure. You're the architect.
